{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008e1876-8b20-4490-a2bc-0a75a7f3e8a7",
   "metadata": {},
   "source": [
    "## Merging Weather & Flight Data - plus additional cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c5c65-746d-4b49-8bc4-73d90f17d3c5",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ef1fd6-efd3-420e-86d4-a536d499f71f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cddaaf-d78b-40c3-998c-719eb7125db7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### User-set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c7bf263-1c6d-40de-9338-38ed0c7fb093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "weather_data_dir = 'cleaned_output'\n",
    "flight_data_dir = 'filtered_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30d757b8-fe52-46ce-bb84-4d04957ed291",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "timezone_data = pd.read_csv('airport_timezone.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bdacd64-3117-464b-98c9-b1438a973db6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pd.read_csv('filtered_data/filtered_2018').info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a37f74-6686-4fb7-b3e6-c269a8370489",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539ea24b-7ce5-4d22-b3c9-42585f0abe66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rounddown(x):\n",
    "    #round a number down to the nearest hundredth -do this to convert HHmm to nearest hour before\n",
    "    if (int(x) % 100 == 0):\n",
    "        return int(x)\n",
    "    else:\n",
    "        return (int(x) - int(x) % 100)\n",
    "\n",
    "def split_datetime(df):\n",
    "    #for a given weather dataframe, convert the DATE column to include only the date,\n",
    "    #and create a new TIME column to include the time formatted HHmm\n",
    "    date_col = [df['DATE'][i].split(' ')[0] for i in range(len(df['DATE']))]\n",
    "    time_col = [df['DATE'][i].split(' ')[1][:-3].replace(':','') for i in range(len(df['DATE']))]\n",
    "    df['DATE'] = date_col\n",
    "    df['TIME'] = time_col\n",
    "\n",
    "def convert_date(date_col):\n",
    "    #convert string date into date object\n",
    "    converted_date_col = [datetime.strptime(x, '%Y-%m-%d').date() for x in date_col]\n",
    "    return converted_date_col\n",
    "    \n",
    "def hour_col(df):\n",
    "    #for a given dataframe, create a new hour column from each time column. \n",
    "    #This will be used to join weather & flight data by nearest hour\n",
    "    if 'CRSDepTime' in df.columns:\n",
    "        df['CRSDepHr'] = [rounddown(x) for x in df['CRSDepTime']]\n",
    "    if 'CRSArrTime' in df.columns:\n",
    "        df['CRSArrHr'] = [rounddown(x) for x in df['CRSArrTime']]\n",
    "    if 'TIME' in df.columns:\n",
    "        df['HOUR'] = [rounddown(x) for x in df['TIME']]\n",
    "        \n",
    "def days_near_last_hol(df):\n",
    "    #takes in flight dataframe, adds columns for the number of days until and since the last (US) holiday\n",
    "    #holidays considered: Halloween, US Thanksgiving, Christmas Eve, Christmas, New Year's Eve, New Year's Day, MLK Jr Day\n",
    "    #0 means: day is a holiday. Halloween considered so Nov 1st isn't treated as holiday, and 2024 Valentine's day is considered as an upper cap\n",
    "    thanksgiving_dates = ['2018-11-22', '2019-11-28','2020-11-26','2021-11-25','2022-11-24','2023-11-23']\n",
    "    mlk_dates = ['2019-01-21','2020-01-20','2021-01-18','2022-01-17','2023-01-16','2024-01-15']\n",
    "    halloween_dates = [str(y) + '-10-31' for y in range(2018,2024)]\n",
    "    xmas_eve_dates = [str(y) + '-12-24' for y in range(2018,2024)]\n",
    "    xmas_day_dates = [str(y) + '-12-25' for y in range(2018,2024)]\n",
    "    nye_dates = [str(y) + '-12-31' for y in range(2018, 2024)]\n",
    "    nyd_dates = [str(y) + '-01-01' for y in range(2019,2025)]\n",
    "    val_day_2024_date = ['2024-02-14']\n",
    "    holidays = [halloween_dates, thanksgiving_dates, mlk_dates, xmas_eve_dates, xmas_day_dates, nye_dates, nyd_dates,val_day_2024_date]\n",
    "    hol_dates = [x for xs in holidays for x in xs] #inspired by https://stackoverflow.com/a/952952\\\n",
    "    #convert from str to datetime.date format\n",
    "    flightdates = convert_date(df['FlightDate'])\n",
    "    hol_dates = convert_date(hol_dates)\n",
    "    #create days until holiday column: min(holiday - flightdate), where holiday is not before flightdate\n",
    "    days_until = [min([(hdate - x).days for hdate in hol_dates if hdate >= x]) for x in flightdates] \n",
    "    #create days since holiday column: min(flightdate - holiday), where holiday is not after flightdate\n",
    "    days_after = [min([(x - hdate).days for hdate in hol_dates if hdate <= x]) for x in flightdates]\n",
    "    df['DaysUntilHol'] = days_until\n",
    "    df['DaysAfterHol'] = days_after\n",
    "    \n",
    "def convert_timezone(df, airport_type):\n",
    "    for i in range(len(df['Time_Zone'])):\n",
    "        time_change = 0 #will remain 0 for CST locations\n",
    "        \n",
    "        if df['Time_Zone'][i] == 'EST':\n",
    "            time_change = -100\n",
    "        elif df['Time_Zone'][i] == 'MST':\n",
    "            time_change = 100\n",
    "        elif df['Time_Zone'][i] == 'PST':\n",
    "            time_change = 200\n",
    "        elif df['Time_Zone'][i] == 'AKST':\n",
    "            time_change = 300\n",
    "        elif df['Time_Zone'][i] == 'HAST':\n",
    "            time_change = 400\n",
    "\n",
    "        if airport_type == 'Origin':\n",
    "            df.loc[i,'CRSDepTime'] == df['CRSDepTime'][i] + time_change\n",
    "            df.loc[i,'DepTime'] == df['DepTime'][i] + time_change\n",
    "        else: #airport_type == 'Dest'\n",
    "            df.loc[i,'CRSArrTime'] == df['CRSArrTime'][i] + time_change\n",
    "            df.loc[i,'ArrTime'] == df['ArrTime'][i] + time_change\n",
    "    print('finished processing for ' + airport_type)\n",
    "    #special handling for when converted CRS time(s) alter FlightDate?\n",
    "            \n",
    "            \n",
    "def convert_to_cst(flight_season_data, timezone_data):\n",
    "    #convert time to cst for all flight data csvs\n",
    "    #if converting time will change date (e.g. roll back 1 hour will push date back to previous day), update FlightDate too\n",
    "    with_origin_tz = pd.merge(\n",
    "        left = flight_season_data,\n",
    "        right = timezone_data,\n",
    "        how = 'inner',\n",
    "        left_on = flight_season_data['Origin'],\n",
    "        right_on = timezone_data['Airport_Code'])\n",
    "    convert_timezone(with_origin_tz, 'Origin')\n",
    "    flight_season_data = with_origin_tz.drop(columns=['Airport_Code','Time_Zone','key_0'])\n",
    "    with_dest_tz = pd.merge(\n",
    "        left = flight_season_data,\n",
    "        right = timezone_data,\n",
    "        how = 'inner',\n",
    "        left_on = flight_season_data['Dest'],\n",
    "        right_on = timezone_data['Airport_Code'])\n",
    "    convert_timezone(with_dest_tz, 'Dest')\n",
    "    flight_season_data = with_dest_tz.drop(columns=['Airport_Code','Time_Zone','key_0'])\n",
    "    \n",
    "    print('finished converting times')\n",
    "    return flight_season_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5671c034-9b54-4638-93a3-d8895ed9cc1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Consolidation & Merging Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3e9787-9021-418b-be2a-da003d21a593",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def consolidate_weather(weather_data_dir):\n",
    "    #pull each airport weather csv, add airport code & hour cols\n",
    "    #consolidate all airports' weather data & write to separate csv\n",
    "    weather_dfs = []\n",
    "    \n",
    "    for file in os.listdir(weather_data_dir): \n",
    "        if '.ipynb' not in file and 'weather' not in file: #avoid trying to parse existing consolidation\n",
    "            airport_code = file[:-4] #remove the '.csv' to get just airport code\n",
    "            file_df = pd.read_csv(os.path.join(weather_data_dir, file))\n",
    "            file_df['AIRPORT_CODE'] = airport_code\n",
    "            split_datetime(file_df)\n",
    "            hour_col(file_df)\n",
    "            weather_dfs.append(file_df)\n",
    "        \n",
    "    weather_data = pd.concat(weather_dfs)\n",
    "    weather_data.to_csv(os.path.join(weather_data_dir, 'weather.csv'), index=False)\n",
    "    print('weather data consolidation complete!')\n",
    "    \n",
    "    \n",
    "def unify_weather_flight(flight_data_dir, weather_data_dir):\n",
    "    weather_data = pd.read_csv(os.path.join(weather_data_dir, 'weather.csv'))\n",
    "    flight_weather_dfs = []\n",
    "    \n",
    "    for file in os.listdir(flight_data_dir):\n",
    "        flight_season_data = pd.read_csv(os.path.join(flight_data_dir, file))\n",
    "        days_near_last_hol(flight_season_data) #get holiday closeness columns\n",
    "        flight_season_data = convert_to_cst(flight_season_data,timezone_data)\n",
    "        hour_col(flight_season_data) #need hour cols to match hourly weather rows\n",
    "        #first merge to get arrival airport weather:\n",
    "        with_arr_weather = pd.merge(\n",
    "            left = flight_season_data, \n",
    "            right = weather_data, \n",
    "            how = 'inner', \n",
    "            left_on = ['Dest', 'FlightDate','CRSDepHr'],\n",
    "            right_on = ['AIRPORT_CODE','DATE','HOUR'])\n",
    "        #then merge again to get departure airport weather:\n",
    "        flight_season_with_weather = pd.merge(\n",
    "            left = with_arr_weather,\n",
    "            right = weather_data,\n",
    "            how = 'inner',\n",
    "            left_on = ['Origin', 'FlightDate','CRSDepHr'],\n",
    "            right_on = ['AIRPORT_CODE','DATE','HOUR'],\n",
    "            suffixes = ('_DEST','_ORIGIN')) #suffix to distinguish weather data\n",
    "        #drop extraneous columns:\n",
    "        flight_season_with_weather.drop(columns=['DATE_DEST','DATE_ORIGIN','AIRPORT_CODE_DEST','AIRPORT_CODE_ORIGIN','HOUR_DEST','HOUR_ORIGIN'])\n",
    "        flight_weather_dfs.append(flight_season_with_weather)\n",
    "        print('processed ' + file)\n",
    "    \n",
    "    flight_weather_data = pd.concat(flight_weather_dfs)\n",
    "    flight_weather_data.to_csv('flight_weather.csv', index=False)\n",
    "    print('data unification complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430fb653-524f-4ca9-9036-f6c16c13d983",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#consolidate_weather(weather_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453c836-f208-4f22-93f3-6f8070dd210e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95db410b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\armer\\AppData\\Local\\Temp\\ipykernel_18156\\1962729451.py:21: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  weather_data = pd.read_csv(os.path.join(weather_data_dir, 'weather.csv'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing for Origin\n",
      "finished processing for Dest\n",
      "finished converting times\n",
      "processed filtered_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\armer\\AppData\\Local\\Temp\\ipykernel_18156\\1962729451.py:25: DtypeWarning: Columns (12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  flight_season_data = pd.read_csv(os.path.join(flight_data_dir, file))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished processing for Origin\n",
      "finished processing for Dest\n",
      "finished converting times\n",
      "processed filtered_2019.csv\n",
      "finished processing for Origin\n",
      "finished processing for Dest\n",
      "finished converting times\n",
      "processed filtered_2021.csv\n",
      "finished processing for Origin\n",
      "finished processing for Dest\n",
      "finished converting times\n",
      "processed filtered_2022.csv\n",
      "finished processing for Origin\n",
      "finished processing for Dest\n",
      "finished converting times\n",
      "processed filtered_2023.csv\n",
      "data unification complete!\n"
     ]
    }
   ],
   "source": [
    "unify_weather_flight(flight_data_dir, weather_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1938eee6-21d1-4398-9d84-c78f9b735464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\armer\\AppData\\Local\\Temp\\ipykernel_18156\\494517200.py:1: DtypeWarning: Columns (36,38,39,56,58,59) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  all_data = pd.read_csv('flight_weather.csv')\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv('flight_weather.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7599adcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = all_data.head(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad41d9ea-f317-4878-9266-be3cb411d42a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 66 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   DayOfWeek                         10000 non-null  int64  \n",
      " 1   FlightDate                        10000 non-null  object \n",
      " 2   Marketing_Airline_Network         10000 non-null  object \n",
      " 3   Origin                            10000 non-null  object \n",
      " 4   Dest                              10000 non-null  object \n",
      " 5   CRSDepTime                        10000 non-null  int64  \n",
      " 6   DepTime                           9856 non-null   float64\n",
      " 7   DepDelay                          9856 non-null   float64\n",
      " 8   CRSArrTime                        10000 non-null  int64  \n",
      " 9   ArrTime                           9848 non-null   float64\n",
      " 10  ArrDelay                          9825 non-null   float64\n",
      " 11  Cancelled                         10000 non-null  int64  \n",
      " 12  CancellationCode                  151 non-null    object \n",
      " 13  Diverted                          10000 non-null  int64  \n",
      " 14  AirTime                           9825 non-null   float64\n",
      " 15  Flights                           10000 non-null  int64  \n",
      " 16  Distance                          10000 non-null  int64  \n",
      " 17  CarrierDelay                      1261 non-null   float64\n",
      " 18  WeatherDelay                      1261 non-null   float64\n",
      " 19  NASDelay                          1261 non-null   float64\n",
      " 20  SecurityDelay                     1261 non-null   float64\n",
      " 21  LateAircraftDelay                 1261 non-null   float64\n",
      " 22  DaysUntilHol                      10000 non-null  int64  \n",
      " 23  DaysAfterHol                      10000 non-null  int64  \n",
      " 24  CRSDepHr                          10000 non-null  int64  \n",
      " 25  CRSArrHr                          10000 non-null  int64  \n",
      " 26  DATE_DEST                         10000 non-null  object \n",
      " 27  STATION_DEST                      10000 non-null  object \n",
      " 28  LATITUDE_DEST                     9991 non-null   float64\n",
      " 29  LONGITUDE_DEST                    9991 non-null   float64\n",
      " 30  NAME_DEST                         9991 non-null   object \n",
      " 31  HourlyDewPointTemperature_DEST    10000 non-null  float64\n",
      " 32  HourlyDryBulbTemperature_DEST     10000 non-null  float64\n",
      " 33  HourlyPrecipitation_DEST          10000 non-null  object \n",
      " 34  HourlySeaLevelPressure_DEST       10000 non-null  float64\n",
      " 35  HourlyStationPressure_DEST        10000 non-null  float64\n",
      " 36  HourlyVisibility_DEST             9901 non-null   object \n",
      " 37  HourlySkyConditions_DEST          9894 non-null   object \n",
      " 38  HourlyWindDirection_DEST          8587 non-null   object \n",
      " 39  HourlyWindSpeed_DEST              10000 non-null  object \n",
      " 40  DailySnowDepth_DEST               10000 non-null  float64\n",
      " 41  DailySnowfall_DEST                10000 non-null  float64\n",
      " 42  REPORT_TYPE_DEST                  10000 non-null  object \n",
      " 43  AIRPORT_CODE_DEST                 10000 non-null  object \n",
      " 44  TIME_DEST                         10000 non-null  int64  \n",
      " 45  HOUR_DEST                         10000 non-null  int64  \n",
      " 46  DATE_ORIGIN                       10000 non-null  object \n",
      " 47  STATION_ORIGIN                    10000 non-null  object \n",
      " 48  LATITUDE_ORIGIN                   10000 non-null  float64\n",
      " 49  LONGITUDE_ORIGIN                  10000 non-null  float64\n",
      " 50  NAME_ORIGIN                       10000 non-null  object \n",
      " 51  HourlyDewPointTemperature_ORIGIN  10000 non-null  float64\n",
      " 52  HourlyDryBulbTemperature_ORIGIN   10000 non-null  float64\n",
      " 53  HourlyPrecipitation_ORIGIN        10000 non-null  object \n",
      " 54  HourlySeaLevelPressure_ORIGIN     10000 non-null  float64\n",
      " 55  HourlyStationPressure_ORIGIN      10000 non-null  float64\n",
      " 56  HourlyVisibility_ORIGIN           10000 non-null  object \n",
      " 57  HourlySkyConditions_ORIGIN        10000 non-null  object \n",
      " 58  HourlyWindDirection_ORIGIN        9033 non-null   object \n",
      " 59  HourlyWindSpeed_ORIGIN            10000 non-null  object \n",
      " 60  DailySnowDepth_ORIGIN             10000 non-null  float64\n",
      " 61  DailySnowfall_ORIGIN              10000 non-null  float64\n",
      " 62  REPORT_TYPE_ORIGIN                10000 non-null  object \n",
      " 63  AIRPORT_CODE_ORIGIN               10000 non-null  object \n",
      " 64  TIME_ORIGIN                       10000 non-null  int64  \n",
      " 65  HOUR_ORIGIN                       10000 non-null  int64  \n",
      "dtypes: float64(26), int64(15), object(25)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "test_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a59f3c6-07df-4f33-b2d4-e14a970adda2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>DaysUntilHol</th>\n",
       "      <th>DaysAfterHol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>4</td>\n",
       "      <td>2018-11-15</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>7</td>\n",
       "      <td>2018-11-25</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1800 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      DayOfWeek  FlightDate  DaysUntilHol  DaysAfterHol\n",
       "200           4  2018-11-15             7            15\n",
       "201           4  2018-11-15             7            15\n",
       "202           4  2018-11-15             7            15\n",
       "203           4  2018-11-15             7            15\n",
       "204           4  2018-11-15             7            15\n",
       "...         ...         ...           ...           ...\n",
       "1995          7  2018-11-25            29             3\n",
       "1996          7  2018-11-25            29             3\n",
       "1997          7  2018-11-25            29             3\n",
       "1998          7  2018-11-25            29             3\n",
       "1999          7  2018-11-25            29             3\n",
       "\n",
       "[1800 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[['DayOfWeek','FlightDate','DaysUntilHol','DaysAfterHol']][200:2000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
